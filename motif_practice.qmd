---
title: "motif_practice"
author: "Andrew"
date: "11/4/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

## Package stuff setup

```{r}
# development stuff
library(devtools)
library(roxygen2)
library(lintr)
library(testthat)
library(httpgd)
library(lobstr) # show details of objects (like str) in a visual way
# wrap a function in ast() to see the structure
library(bannerCommenter) # for banner comments

# other
library(tidyr)
```

Set up the plotting server:

```{r}
hgd() # start the server
httpgd::hgd_browse() # open the browser
dev.off() # close the server
plot(cars)

```

## Package workflow

```{r}
devtools::check()
# usethis::use_tidy_description()
# usethis::use_package("ggplot2", min_version = TRUE)
```

## Package dependencies and setup

This depends on the use of HierarchIcal based Motif Enumeration (HIME), which is
a variable length motif detection algorithim developed by [Gao and Lin (2017)](https://doi.org/10.1109/ICDM.2017.8356939).
The supporting webpage is available
[here](https://sites.google.com/site/himeicdm/).
To use the mimics package, you will need to download the HIME source code, which is
provided via a [GitHub repository](https://github.com/flash121123/HIME).
Download and extract the ZIP file. By default, mimics will look for this folder
in your current R project working directory, but you can place it anywhere on
your computer.

![hime](images/hime-1.png)

An example working directory structure to get started with is shown below.

```text
.
├── HIME-master
├── data
│   └── audio
│       ├── site1
│       ├── site2
│       ├── site3
│       └── site4
├── my-project.Rproj
└── output
```

## Todo

- add warnings that functions will attempt to create files and folders
- .Platform$OS.type
  - check and set function depending on OS
  - or make all PS functions
- full workflow template (plug and play mode)
- generate spectrograms
- plots
- summary statistics
- maps showing study site locations
- import metadata (temp, sensor locations, habitat type)
- Generate a summary description sentences and/or a markdown table
  (automatically generated using in-text R) based on the metadata. e.g.
  - This site has _properties_ and is located _sitelocation_.
- a way to label / confirm motifs in R??
- should have finer scale options for generating plots if you want to. like just returning
returning the plot as an object instead of saving them all?

## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Testing

Testing setup in progress.

## Install/reinstall

```{r}
detach("package:MIMiCS", unload = TRUE)
install("/Users/andrew/Documents/GitHub/mimics")
library(MIMiCS)
```

## Terminology

- Site = a geographic region/area
- Location = an actual sensor

## Step 1 - prepare the acoustic indices data

### Download or provide your own data

In this example workflow we will use data available from the A2O.

If you would like to download data from the A20, follow this guide (TODO
refactor this into own section).

Note, if you're using a folder like me called A2O, make sure you double check
whether you are using a capital O or a zero 0. I've made that mistake :)

```{r}
list.files(path = "data/A2O-mini", recursive = TRUE)
```

```text
data
├── A20
    ├── 305_BooroopkiDryA
    │   ├── 20201230T050000+1100_Booroopki-Dry-A_271849.flac
    │   ├── 20201230T070000+1100_Booroopki-Dry-A_271857.flac
    │   ├── 20201230T090000+1100_Booroopki-Dry-A_271854.flac
    │   ├── 20201231T050000+1100_Booroopki-Dry-A_271865.flac
    │   ├── 20201231T070000+1100_Booroopki-Dry-A_271867.flac
    │   └── 20201231T090000+1100_Booroopki-Dry-A_271866.flac
    ├── 307_BooroopkiDryB
    │   ├── 20201230T050000+1100_Booroopki-Dry-B_278581.flac
    │   ├── 20201230T070000+1100_Booroopki-Dry-B_278580.flac
    │   ├── 20201230T090000+1100_Booroopki-Dry-B_278587.flac
    │   ├── 20201231T050000+1100_Booroopki-Dry-B_278593.flac
    │   ├── 20201231T070000+1100_Booroopki-Dry-B_278600.flac
    │   └── 20201231T090000+1100_Booroopki-Dry-B_278597.flac
    ├── 6_BonBonStationDryA
    │   ├── 20201230T050000+1030_Bon-Bon-Station-Dry-A_418011.flac
    │   ├── 20201230T070000+1030_Bon-Bon-Station-Dry-A_418014.flac
    │   ├── 20201230T090000+1030_Bon-Bon-Station-Dry-A_418017.flac
    │   ├── 20201231T050000+1030_Bon-Bon-Station-Dry-A_418021.flac
    │   └── 20201231T070000+1030_Bon-Bon-Station-Dry-A_418020.flac
    └── 8_BonBonStationDryB
        ├── 20201230T050000+1030_Bon-Bon-Station-Dry-B_426598.flac
        ├── 20201230T070000+1030_Bon-Bon-Station-Dry-B_426601.flac
        ├── 20201230T090000+1030_Bon-Bon-Station-Dry-B_426596.flac
        ├── 20201231T050000+1030_Bon-Bon-Station-Dry-B_426604.flac
        └── 20201231T070000+1030_Bon-Bon-Station-Dry-B_426607.flac
```

See some summary information about the files you're working with. My files are
from __. From two sites, and two locations within each site.

```{r}
# TODO: nice summary info, number of recordings/files, total hours, total sites
```

### Calculate acoustic indices

We will now calculate acoustic indices using a wrapper function to call the
`AnalysisPrograms` software. At the moment, `motifR` supports the folder
structure that is generated by `AP` only. In the future, different folder
structures may be supported. Note: If you have already generated indices with AP
you can skip this step. Or else you can generate the indices directly in your
terminal with AP.

#### Check if AP is available

If you don't have AP installed, visit this
[link](https://ap.qut.ecoacoustics.info/).
Problem: The path in RStudio terminal doesn't match the path in the system
terminal. I can call `AP` in a terminal, but not in Rstudio terminal. The PATH
imported into Rstudio, Rstudio terminal, both seem to be different. Run
`Sys.getenv("PATH")` in an Rmarkdown document, and then run `echo $PATH` in
Rstudio terminal. Using the below code adds `/Users/andrew/.local/bin` to my
path for Rstudio but not Rstudio terminal. This is the path to AP for my system
(based on the automatic installer for AP). Still need to test this flow on
windows.  

Check your value for path in R terminal. echo $PATH and compare to a real
terminal.

```{r}
# check a package you know should be available on your path
find_program("ffmpeg")

# check if AP is available
MIMiCS::find_program("AP")

# if you have installed AP but the above does not work, try the code below:
old_path <- Sys.getenv("PATH")
Sys.setenv(PATH = paste(old_path, "/Users/andrew/.local/bin", sep = ":"))
# now check AP again
# find_program("AP")
```

#### Errors in sound files - what happens?

Lets generate indices. All audio should be in one folder per study site (i.e.
recorder location).

```{r}
# AP_prepare("data/A2O_with_errors/", "output/indices-output-ap")
```

You might notice in the above example I used the input directory
`A2O_with_errors/`. This is data that I downloaded fresh from A2O. But I called
it this because I tried to run AP and already know it has errors, and wanted to
keep it as is to demonstrate what happens if you come across this issue. The
error given is: `System.FormatException: Failed parsing 'N/A' to get FORMAT
duration.` Nowadays, all files uploaded to A2O are automatically checked for
errors and fixed. But older files may still have errors. These files are from
January 2021 and have an issue. But don't worry, it is fixable and I will show
you how. If your files are OK you can skip this step.

We can run emu:

```{r}
# get the metadata from a2O files and output as a .csv

# fix broken audio files
# pay attention to the ' (doesn't work in mac for some reason) and directory
# structure. use backslashes to escape a space. use cd to check if your path is
# correct.
# cd ~/Documents/Data\ Science/Projects/Ecoacoustics/motifR/data/A2O/

# check the files
# ./emu fix check --all ~/Documents/Data\ Science/Projects/Ecoacoustics/motifR/data/A2O/**/*.flac

# the files have the FL010 metadata bug

# fix the files (dry run)
# ./emu fix apply -f FL010 --dry-run ~/Documents/Data\ Science/Projects/Ecoacoustics/motifR/data/A2O/**/*.flac

# real run
# ./emu fix apply -f FL010 ~/Documents/Data\ Science/Projects/Ecoacoustics/motifR/data/A2O/**/*.flac
```

#### Generating indices on fixed sound files

Now that I've fixed the files, i'll try to run AP analysis again. This will take
some time. If you had errors, clear the `indices-output` folder before running
this step on your fixed audio. Remember that AP generates values for acoustic
indices based on each 1 minute segment of audio.

```{r}
AP_prepare("data/A2O-mini", "output/indices-output-ap-mini")
```

![Example output](motif_practice_insertimage_1.png)

- todo update this example output

## Step 2 - Time series

Construct a time series for the acoustic indices. Here the data is output to a
folder but we also save it to a data frame (which will be used in step 4). #TODO
explaing this better / do we need to have both options?

Motifs have to be run ecosystems and months separately.

```{r}
# Notes from time_series.R to remember: ======

# next we run the motif analysis based on a geographic and month subset
# loop and make big df with all
# subset into geo and month id
# drop columns and get 1 df per index
# run hime per month, per geo, per index - keep DF as is and when doing hime, subset what you want and then run (but it has to be ordered - ordering files function - date, time, result minutes)
# hime takes .txt files
# hime runs on pwsh from R
# have to save the results files from hime
# can output everything in same directory
# set seed - when randomizing the labels etc for reproducible example important to set seed
# if they want to try follow they should get exactly same result, for RF and everything.
```

```{r}
# run the time_series
# output is a data frame of all indices data combined
# but this function also creates a folder, which stores the subset indices data that will be used for HIME input

# TODO: might need a function to return the dataframe without creating outputs again? but if you need to create the dataframe again its probably safesty to re-run the subsequent steps anyway, for consistency

# IMPORTANT: the time_series function relies on your file times and dates being
# labelled correctly. Otherwise it will not function correctly. The time series
# being ordered is a critical step in the process.

my_indices_data <-
  time_series(
    indicesfolder = "output/indices-output-ap-mini",
    outputfolder = "output/timeseries-mini"
  )
```

Saving the csv here for testing purposes:

```{r}
write.csv(my_indices_data, "tests/testthat/testdata/my_indices_data.csv", row.names = FALSE)

my_indices_data <- read.csv(
  file =
    "tests/testthat/testdata/my_indices_data.csv"
)
colnames(my_indices_data)
```

## Step 3 - HIME

Starts with hime, hime processing, and then hime_processing_cont

Hime can be used in a terminal if you like. `run_hime` is just a helpful wrapper
function that calls HIME on each of the acoustic index time series files, and
stores the output in text files with names, and in a separate directory. By
default, the funciton will look for the HIME folder in your current working
directory. But you can optionally specify a direct path using the argument
`himepath`.

- TODO Add a warning: output directory contains files. May overwrite existing file
types please check this is what you want to do. Or, add an option that if
duplicate names detected, add suffix to file name.

```{r}

run_hime(
  timeseriesdata = "output/timeseries-mini",
  himeoutput = "output/hime"
)
```

## Step 4 - generating some plots

Generates some time series / motif plots. Also outputs the motifs.csv files
(motif + timeseries data combined).

```{r}
debugOnce(MIMiCS::motif_plots)
# undebug(MIMiCS::motif_plots)
MIMiCS::motif_plots(
  data_indices_all = my_indices_data,
  outputfigures = "output/figures",
  himedatapath = "output/hime-clean"
)

motif_ts_results <- motif_plot_master(
  my_indices_data = my_indices_data,
  outputfigures = "output/figures",
  himepath = "output/hime-clean",
  threshold = 0.9
)
```

`-- up to this point is working --`

## Step 5 -

-step6: 6_CompleteMotif ---- -step7: 7_CropSpectrogram ---- -step8:
8_FeatureExtraction ---- ATM this is called wavelet.R but might change. CHANGE
to feature extraction

```{r}
feature_extraction(
  data_indices_all = my_indices_data,
  himeclean = "output/hime-clean",
  outputspecpath = "output/specs",
  indicespath = "output/indices-output-ap-mini",
  outwavelet = "output/wavelets"
)
str(my_indices_data)

```

- master spreadsheet
- column with label type: manual vs forest


```{r}
# get the names of the motif DFs
has_motifs <- names(motif_ts_results$motif_dfs)

# filter the time series to just the ones with motifs
motif_ts_has_motifs <- motif_ts_results$ts_motifs[has_motifs]
```

- test with one data frame and then lapply after

Step 1: split by filename
EVN = Events per second
ENT = Entropy
ACI = AcousticComplexity
```{r}
test <- motif_ts_has_motifs[[1]]

# split by unique filename
test_split <- split(test, test$FileName)
# the names of this output are the unique filenames
names(test_split)
# for each filename, get the acoustic index name
# which is always index 1 in the column names
index_names <- lapply(test_split, function(x) names(x)[1])

# lets work through using index position 1 for now
# show the folder name:
names(index_names)[[1]]
# show the acoustic index name for the file we want:
index_names[[1]]

# convert the index name to the abbreviation
index_names_2 <- lapply(index_names, function(x) {
  if (x == "EventsPerSecond") {
    "EVN"
  } else if (x == "Entropy") {
    "ENT"
  } else if (x == "AcousticComplexity") {
    "ACI"
  }
})

# look for the spectrograms
# we are looking in output/indices-output-ap-mini, recursively
# look in this folder:
matching_folder <- get_data_path(
  "output/indices-output-ap-mini",
  paste0(names(index_names_2)[[1]], ".flac")
)

# search the matching folder for the index name, with extension .png
matching_image <- list.files(matching_folder,
  pattern =
    paste0(index_names_2[[1]], ".png"), recursive = TRUE, full.names = TRUE
)

# stop if not length 1
if (length(matching_image) != 1) {
  stop("Error: could not find matching image")
}

matching_df <- test_split[[1]]
# we already filtered for dataframes that contain motifs
# summarise this dataframe so that there is only one row per motif
# with the start and end time of the motif, which is a numeric value from the
# position column
# TODO: important note: there are some short motifs here, I can't remember if I
# added the step that short motifs or if that works or not. But I just realised it
# isn't that necessary perhaps because you can get the start position and the length
matching_df_summarised <- matching_df %>%
  dplyr::group_by(motif, length) %>%
  # remove NA rows
  dplyr::filter(!is.na(motif)) %>%
  dplyr::summarise(
    start = min(position)
    # length = length
  ) %>%
  dplyr::arrange(start)
# add end column which is start + length
matching_df_summarised_new <- matching_df_summarised %>%
  dplyr::mutate(end = start + length)
```

```{r}
# now we have the matching_image, and the matching_df_summarised_new
# for each row in the matching_df_summarised_new, we want to crop the image
# and save it to a new folder
# output/cropped
# filename for each image will be the original image name, plus the motif name
# and the start and end time
# create the list of image names
# this is vectorised so it creates a list of the same length as the number of
# rows, even though only one image name is used
# remove .png from the matching image name
# remove last four characters from the matching image name
matching_image_name <- substr(matching_image, 1, nchar(matching_image) - 4)

# create the image names
image_names <- paste0(
  basename(matching_image_name),
  "_",
  matching_df_summarised_new$motif,
  "_",
  matching_df_summarised_new$start,
  "-",
  matching_df_summarised_new$end,
  ".png"
)

# create full path for image names
image_names_full_output <- get_data_path("output/cropped", image_names)
```

```{r}
# now we read in matching_image, and crop it for each row in the
# matching_df_summarised_new
# we want to crop the image to the start and end time of the motif
# we want to save the cropped image to the output/cropped folder
lapply(seq_len(nrow(matching_df_summarised_new)), function(row) {
  # read in the image
  img <- magick::image_read(matching_image)
  # crop the image
  img_crop <- magick::image_crop(
    img,
    magick::geometry_area(
      height = 316, # 256,
      width = matching_df_summarised_new$length[row] - (1 - matching_df_summarised_new$start[row]),
      # y_off = 20, # cropping offset don't touch
      x_off = matching_df_summarised_new$start[row]
    )
  )
  # save the image
  magick::image_write(img_crop, image_names_full_output[row])
})
# this works because the spectrogram images are 120 pixels wide, 1 pixel per
# second, so the result minute is used to crop based on pixels.
# in the df. there is an end position of 146, which is greater than the width of
# the image, so the resulting crop is actually only 112 to 120 pixels and very
# narrow / hard to see

```

- this works above.
- below: alternate method to get higher quality spectrogram crops

```{r}
# take the matching image, and source the sound file that it was created from
# then crop the sound file to the start and end time of the motif
matching_sound <- basename(matching_image)
# remove the suffix "__.*.png"
matching_sound <- gsub("__.*.png", "", matching_sound)
# search the original sound folder used for the matching sound
# data/A2O-mini
extension <- ".flac"
# do this because file names will probably contain regex characters such as +
# which will cause problems with the pattern matching
matching_sound_escaped <- stringr::str_escape(matching_sound)
matching_sound_file <- list.files(
  get_data_path("data/A2O-mini"),
  pattern = paste0(matching_sound_escaped, extension),
  recursive = TRUE,
  full.names = TRUE
)
```

- create a dataframe that shows the motifs (motif and match name), the cropped
spectrogram link, and a field for classification type (manual or forest), and
classification (insect, bird, frog, etc)
  
```{r}
# create a dataframe with the motif and match name
# and the cropped spectrogram link
# and a field for classification type (manual or forest)
# and classification (insect, bird, frog, etc)
# and the filename
```

- this will require ffmpeg installed and available on path
  
```{r}
# quick fix for length past file end
matching_df_summarised_new[4, 4] <- 120
matching_df_summarised_new$file_name <- matching_sound_file
crop_convert_audio <- function(df, output_dir) {
  output_dir <- get_data_path(output_dir)
  # Loop through each row of the input dataframe
  for (i in seq_len(nrow(df))) {
    # Construct input and output file paths
    file_name <- df[[i, "file_name"]]
    basename_out <- basename(file_name)

    input_file <- file.path(file_name)
    output_file <- file.path(output_dir, paste0(df[i, "motif"], "_", basename_out))

    # Construct ffmpeg command to crop audio file
    # convert minutes to seconds
    start <- df[i, "start"] * 60
    end <- df[i, "end"] * 60

    crop_cmd <- paste0(
      "ffmpeg -i ", shQuote(input_file),
      " -ss ", start, " -to ", end,
      " -c copy ", shQuote(output_file)
    )

    # Execute ffmpeg command to crop audio file
    system(crop_cmd)

    # Convert cropped audio file to .wav format
    # With a new name
    basename_out_trim <- gsub(".flac", "", basename_out)
    output_file_wav <- file.path(output_dir, paste0(
      basename_out_trim, "_", df[[i, "motif"]], "_", format(df[[i, "start"]], nsmall = 2, trim = TRUE), "-",
      format(df[[i, "end"]], nsmall = 2, trim = TRUE), ".wav"
    ))

    convert_cmd <- paste0(
      "ffmpeg -i ", shQuote(output_file),
      " -acodec pcm_s16le -ac 1 -ar 44100 ",
      shQuote(output_file_wav)
    )

    # Execute ffmpeg command to convert cropped audio file to .wav format
    system(convert_cmd)
    # Remove the cropped flac that was converted
    file.remove(output_file)
  }
}

crop_convert_audio(matching_df_summarised_new, "output/cropped")
```

- you look at the spectrogram from the insect
- and you are trying to classify what THAT index / spectrogram is capturing
- not what exists in the entire crop
- the classifications can be open 
- anthophony could be car, airplane etc if you are interested in classifying
that, or just anthophony
- could be chickens, cows, goats, could classify as anthophony because not part
of natural environment
- 

